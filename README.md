# Dimentionality-Reduction-using-PCA
## Having multiple features in our dataset can eventually lead our model to oversit wrt training data & make it more complex for understand and debug. Hence its better to always bring down the dimentions from higher to lower.
## Example of Higher to lower dimentions, demographic information of someone could be Age, Income, Gender, type of employement, Location, and so on and its really not advisable to bring all these features into an algorithm rather we can combine all similarly behaving/patters together so all 5 could become 1/2. Thats when PCA comes into play which is unsupervised and makes it easy to bring down dimentions from high to lower by associating similarly behaving attributes/features together. 
## Now in this notebook we have taken sample data, and will try to bring down the features using PCA/Principal Component Analysis. 
## This is not guaranteed approach for gaining accuracy, however we can surely give it a try, also there are other approaches for Dimentionality Reduction like LDA/SVD, which we can try out for better accuracy and making our model more generalized. 

